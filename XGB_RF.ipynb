{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 数据预处理\n",
    "- 异常值检测\n",
    "- 数据归一化处理\n",
    "- 除去相关度低的attribute\n",
    "- 除去方差小的属性\n",
    "- （最后手段）利用主成分分析进行数据降维"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 随机森林实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import ensemble # ensemble learning: 集成学习\n",
    "from sklearn import preprocessing\n",
    "import sklearn.tree as tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9542127591296382\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./OnlineNewsPopularity/OnlineNewsPopularity.csv') \n",
    "# df.head()\n",
    "# print('shares: ', Counter(df[' shares']>1400))   # True 19562; False 20082\n",
    "# print(df[' shares'])\n",
    "y = (df[' shares']>1400)*1\n",
    "X = preprocessing.scale(df.iloc[:, 2:-1])   # 数据归一化\n",
    "# # PCA降维\n",
    "# pca = PCA(n_components=36)  \n",
    "# X_new = pca.fit_transform(X)\n",
    "# print(pca.explained_variance_ratio_.sum()) #降维后信息保留量应大于95%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, \n",
    "                                    test_size=0.3, random_state=12345) # random_state?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 普通决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 直接使用交叉网格搜索来优化决策树模型，边训练边优化\n",
    "# 网格搜索的参数：正常决策树建模中的参数 - 评估指标，树的深度，\n",
    " ## 最小拆分的叶子样本数与树的深度\n",
    "param_grid = {'criterion': ['entropy', 'gini'],\n",
    "             'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "             'min_samples_split': [4, 8, 12, 16, 20, 24, 28]} \n",
    "                # 通常来说，十几层的树已经是比较深了\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()  # 定义一棵树\n",
    "clfcv = GridSearchCV(estimator=clf, param_grid=param_grid, \n",
    "                            scoring='roc_auc', cv=4) \n",
    "        # 传入模型，网格搜索的参数，评估指标，cv交叉验证的次数\n",
    "      ## 这里也只是定义，还没有开始训练模型\n",
    "\n",
    "clfcv.fit(X=X_train, y=y_train)\n",
    "\n",
    "# 使用模型来对测试集进行预测\n",
    "test_est = clfcv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树准确度:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58      5970\n",
      "           1       0.59      0.65      0.62      5924\n",
      "\n",
      "    accuracy                           0.60     11894\n",
      "   macro avg       0.60      0.60      0.60     11894\n",
      "weighted avg       0.60      0.60      0.60     11894\n",
      "\n",
      "决策树 AUC:\n",
      "AUC = 0.6022\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "print(\"决策树准确度:\")\n",
    "print(metrics.classification_report(y_test,test_est))  # 列出各项指标\n",
    "print(\"决策树 AUC:\")\n",
    "fpr_test, tpr_test, th_test = metrics.roc_curve(y_test, test_est)\n",
    "print('AUC = %.4f' %metrics.auc(fpr_test, tpr_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 使用随机森林对测试集进行预测\n",
    "param_grid = {\n",
    "    # 'criterion':['entropy','gini'],\n",
    "    # 'max_depth':[5, 6, 7, 8],    # 深度：这里是森林中每棵决策树的深度\n",
    "    'n_estimators':[10, 20, 50, 100, 200, 400],  # 决策树个数-随机森林特有参数\n",
    "    # 'max_features':[0.3,0.4,0.5],\n",
    "    #  # 每棵决策树使用的变量占比-随机森林特有参数（结合原理）\n",
    "    # 'min_samples_split':[4,8,12,16]  # 叶子的最小拆分样本量\n",
    "}\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_cv = GridSearchCV(estimator=rfc, param_grid=param_grid,\n",
    "                      scoring='roc_auc', cv=4)\n",
    "rfc_cv.fit(X_train, y_train)\n",
    "test_est = rfc_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林精确度:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      5991\n",
      "           1       0.64      0.65      0.65      5903\n",
      "\n",
      "    accuracy                           0.65     11894\n",
      "   macro avg       0.65      0.65      0.65     11894\n",
      "weighted avg       0.65      0.65      0.65     11894\n",
      "\n",
      "随机森林 AUC:\n",
      "AUC = 0.6475\n"
     ]
    }
   ],
   "source": [
    "print('随机森林精确度:')\n",
    "print(metrics.classification_report(test_est, y_test))\n",
    "print('随机森林 AUC:')\n",
    "fpr_test, tpr_test, th_test = metrics.roc_curve(test_est, y_test)\n",
    "print('AUC = %.4f' %metrics.auc(fpr_test, tpr_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# xgboost实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9542127356737977\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_csv('./OnlineNewsPopularity/OnlineNewsPopularity.csv') \n",
    "y = (df[' shares']>1400)*1\n",
    "X = preprocessing.scale(df.iloc[:, 2:-1])\n",
    "# # PCA\n",
    "# pca = PCA(n_components=36)  \n",
    "# X_new = pca.fit_transform(X)\n",
    "# print(pca.explained_variance_ratio_.sum()) #降维后信息保留量应大于95%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 训练模型\n",
    "model = xgb.XGBClassifier(learning_rate=0.1, n_estimators=160, objective='binary:logistic')\n",
    "# model = xgb.XGBClassifier(num_class=2, max_depth=5, learning_rate=0.1, n_estimators=160, silent=True, objective='multi:softmax')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 对测试集进行预测\n",
    "ans = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost精确度:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      6234\n",
      "           1       0.62      0.64      0.63      5660\n",
      "\n",
      "    accuracy                           0.64     11894\n",
      "   macro avg       0.64      0.64      0.64     11894\n",
      "weighted avg       0.64      0.64      0.64     11894\n",
      "\n",
      "xgboost AUC:\n",
      "AUC = 0.6432\n"
     ]
    }
   ],
   "source": [
    "print('xgboost精确度:')\n",
    "print(metrics.classification_report(ans, y_test))\n",
    "print('xgboost AUC:')\n",
    "fpr_test, tpr_test, th_test = metrics.roc_curve(ans, y_test)\n",
    "print('AUC = %.4f' %metrics.auc(fpr_test, tpr_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "301a17a29b57d3836b7901af1621afd6d2b1f2298b9c7949191147cf2fea93e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}